{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ProjectML20\n",
    "by Ryan Park and David Li\n",
    "Created from scratch except for first cell\n",
    "training data set:\n",
    "https://www.kaggle.com/ngbolin/mnist-dataset-digit-recognizer/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# abstract:\n",
    "the purpose of this project was to create a machine learning program using the KNeighborsClassifier to precisely predict the pixels of a 28x28 .csv panda created image of one of the numbers 0-9. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Product Results:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have acheived a final accuracy of 98.76%"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "our KNeighborsClassifier paramateers results\n",
    "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "                     metric_params=None, n_jobs=None, n_neighbors=4, p=2,\n",
    "                     weights='distance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is our confusion matrix:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "array([[ 974,    1,    0,    0,    0,    0,    4,    1,    0,    0],\n",
    "       [   0, 1135,    0,    0,    0,    0,    0,    0,    0,    0],\n",
    "       [   4,    4, 1016,    0,    0,    0,    1,    7,    0,    0],\n",
    "       [   0,    0,    2,  995,    1,    6,    0,    5,    0,    1],\n",
    "       [   0,    2,    0,    0,  969,    0,    1,    2,    1,    7],\n",
    "       [   3,    0,    0,    4,    2,  881,    0,    1,    0,    1],\n",
    "       [   1,    4,    0,    0,    0,    1,  952,    0,    0,    0],\n",
    "       [   0,    7,    1,    0,    1,    0,    0, 1013,    0,    6],\n",
    "       [   2,    2,    2,    5,    1,    6,    1,    3,  949,    3],\n",
    "       [   1,    3,    2,    2,    2,    0,    1,    6,    0,  992]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RP bring in the new datasets\n",
    "##DL creating variable and setting it so that it is defined as reading the panda csv file called test.csv\n",
    "test_data = pd.read_csv('test.csv')\n",
    "##DL creating variable and setting it so that it is defined as reading the panda csv file called train.csv\n",
    "train_data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RP All the datasets with \"1\" afterwards are new datasets, so the ml program is trained on different data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RP split into traning data, traning labels, and test values\n",
    "##DL the y_train1 variable is used to train all values that are under the column label in the panda\n",
    "y_train1 = train_data['label'].values\n",
    "##DL the x_train1 is all of the pixels in the columns that are not under the label column\n",
    "X_train1 = train_data.drop(columns=['label']).values\n",
    "##DL the test.csv file does not have any labeling/first row that contains name for all the pixels\n",
    "X_test1 = test_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##RP Book's code, here for my reference\n",
    "##RP but basically imports their own dataset, assigns the x and y strings to integers, and splits the group of numbers up into testing and training\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "mnist.keys()\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "y = y.astype(np.uint8)\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=4, p=2,\n",
       "                     weights='distance')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DL the Kneighbors classifier analayzes based on previous binary classified numbers. \n",
    "#DL n_neighbors decides how many numbers to compare the current row of pixels to\n",
    "#DL we set a parameter of euclidean distance to be more important because we care about how the number looks on the screen\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier(weights='distance', n_neighbors=4)\n",
    "\n",
    "#DL the code that actually trains the program\n",
    "knn_clf.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9876"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DL determines accuracy of our program using sklearn premade accuracy function using the test set\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_knn_pred = knn_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_knn_pred)\n",
    "#RP our accuracy calculated was 98.76% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RP The training dataset comes from a competition, so the testing set's labels are not included. The testing set we used\n",
    "is HOML's testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DL creating a cross validation score using 3 cross folds\n",
    "#RP note: takes a while to load\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(knn_clf, X_test, y_test, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 974,    1,    0,    0,    0,    0,    4,    1,    0,    0],\n",
       "       [   0, 1135,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   4,    4, 1016,    0,    0,    0,    1,    7,    0,    0],\n",
       "       [   0,    0,    2,  995,    1,    6,    0,    5,    0,    1],\n",
       "       [   0,    2,    0,    0,  969,    0,    1,    2,    1,    7],\n",
       "       [   3,    0,    0,    4,    2,  881,    0,    1,    0,    1],\n",
       "       [   1,    4,    0,    0,    0,    1,  952,    0,    0,    0],\n",
       "       [   0,    7,    1,    0,    1,    0,    0, 1013,    0,    6],\n",
       "       [   2,    2,    2,    5,    1,    6,    1,    3,  949,    3],\n",
       "       [   1,    3,    2,    2,    2,    0,    1,    6,    0,  992]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DL import sklearn's confusion matrix and use the y_test/y_knn_pred to graph \n",
    "#DL rows represent actual classes\n",
    "#DL columns represent predicted classes\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test,y_knn_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
